[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MPA Europe - OBIS contribution documentation",
    "section": "",
    "text": "1 Introduction to the OBIS contribution to MPA Europe\nThe EU Horizon project “Marine Protected Areas Europe (MPA Europe, https://mpa-europe.eu) aims to identify the locations within the European seas where MPAs would protect the highest number of species, habitats and ecosystems. This information is crucial to establish a functional MPA network and will help managers to propose further areas for conservation in the future. Innovative and bold, MPA Europe will also go one step further by considering the potential blue carbon benefits of the prioritization.\nOBIS (Ocean Biodiversity Information System) will contribute with three pieces of information which will be supplied to the area prioritization process: (i) species distribution models (SDMs) of at least half of the European marine species; (ii) diversity metrics for European seas; and (iii) habitat maps considering habitat forming species. In all cases, models will be created using OBIS data and will include predictions for future scenarios according to CMIP6."
  },
  {
    "objectID": "index.html#about-this-documentation",
    "href": "index.html#about-this-documentation",
    "title": "MPA Europe - OBIS contribution documentation",
    "section": "1.1 About this documentation",
    "text": "1.1 About this documentation\nTransparency and reproducibility are an integral part of our contribution to the project. Thus, here you will find included all the details about the approaches and decisions we took in each part of the work. This is a complement to the available codes/data."
  },
  {
    "objectID": "studyarea.html",
    "href": "studyarea.html",
    "title": "2  Defining the study area",
    "section": "",
    "text": "Our first effort was in establishing a consistent study area shape that could be used by all the work package teams. Using as a reference the study area portrayed in the MPA Europe technical description, we defined the boundaries of the final shape from a product developed by the Flanders Marine Institute that intersects the Exclusive Economic Zones (EEZ) and the IHO (International Hydrographic Organization) seas map.\n\n\n\nThe study area\n\n\nThe whole process of creating the study area, as well as the produced shapefiles are available at the GitHub repository mpaeu_studyarea."
  },
  {
    "objectID": "datadownload.html#selecting-species-for-modeling",
    "href": "datadownload.html#selecting-species-for-modeling",
    "title": "3  Obtaining occurrence data from OBIS and GBIF",
    "section": "3.1 Selecting species for modeling",
    "text": "3.1 Selecting species for modeling\nThe first step was to establish the species occurring on the study area. We used the robis function dataset to retrieve all species occurring on the study area. Further on we filtered the dataset to:\n\nretain only taxa at the species level\nretain only taxa with accepted taxonomic status\nremove Archaea, Bacteria, Fungi and Protozoa taxa\ninclude only marine or brackish species\n\nFrom that we obtained a final list of 22159 species.\nIn the case of GBIF, we first downloaded all data occurring within our study area. Then, using the worrms package we verified which of those species were marine. Then we performed the same filters used with the OBIS data. This resulted in 22782 unique species."
  },
  {
    "objectID": "datadownload.html#downloading-data",
    "href": "datadownload.html#downloading-data",
    "title": "3  Obtaining occurrence data from OBIS and GBIF",
    "section": "3.2 Downloading data",
    "text": "3.2 Downloading data\nOBIS data was obtained from the full export available at https://obis.org/data/access/. However, code for downloading the data through the robis package is available. This is done through the obissdm package (which is being developed to support this project)\nGBIF data was downloaded using the rgbif package, via the obissdm package."
  },
  {
    "objectID": "datadownload.html#quality-control-steps-under-development",
    "href": "datadownload.html#quality-control-steps-under-development",
    "title": "3  Obtaining occurrence data from OBIS and GBIF",
    "section": "3.3 Quality control steps (under development)",
    "text": "3.3 Quality control steps (under development)\n\n3.3.1 Duplicate records removal\nWe removed duplicated data points using GeoHash with a precision of 6 (width ≤ 1.22km X height 0.61km), and the year. Thus, for each combination of GeoHash cell and year, only one record was kept. That part is implemented in the mp_dup_check function, of the project package msdm.\n\n\n\n\n\n\nNote\n\n\n\nWe note that, specifically for the SDMs, before modeling we do an additional duplicate removal in order to keep only a single record per cell.\n\n\n\n\n3.3.2 Remove records on land\nRecords on land were removed based on openmap.\n\n\n\n\n\n\nNote\n\n\n\nWe further filtered the records for the SDMs by keeping only those overlapping the environmental variable layers (which present some differences to the land layer used before).\n\n\n\n\n3.3.3 Geographical and environmental outliers (flagging)\nFor the assessment of geographical outliers we implemented an innovative method that considers the existence of barriers when calculating the distance between points. Usually, geographical outliers are calculated based on the cartesian distance between the points. However, for marine species (indeed, also for terrestrial ones) the barriers are important because it constrains dispersal. Consider for example one species on the two sides of the Panama strait (Atlantic and Pacific). A straight line between the two points would be a short distance. However, if we take in account the barrier, then the animal (or its larvae) would need to travel a much longer distance to reach the other side of the strait.\nIn both the geographical and the environmental (Sea Surface Temperature, bathymetry and salinity) outlier assessment, we used a threshold of 3 times the inter quantile range to identify extreme points, but we just flagged the most extreme outlier until a limit of 1% of the points (i.e. if there were more points above the threshold, just the most extreme ones were flagged)."
  },
  {
    "objectID": "datamining.html",
    "href": "datamining.html",
    "title": "4  Obtaining additional biodiversity data",
    "section": "",
    "text": "5 Codes for obtaining information from data repositories"
  },
  {
    "objectID": "datamining.html#obisdi-package",
    "href": "datamining.html#obisdi-package",
    "title": "4  Obtaining additional biodiversity data",
    "section": "4.1 obisdi package",
    "text": "4.1 obisdi package\nFor enabling a streamlined and standard ingestion of data throughout the project we developed the obisdi package, which is available on GitHub. The idea behind the package (and basically all the structure) came from the Tracking Invasive Alien Species (TrIAS) project’ checklist recipe (see more here), which provides a standard structure for mapping data to the Darwin Core standard. Using this structure, all the mapping is fully documented and can be tracked. Also, it’s possible to directly ingest the data to the IPT from a GitHub repository.\nEvery project created with the obisdi package have the following structure:\n\na folder for data, containing two other folders - one for raw data (where the original data files are stored) and one for processed data (where the final edited files are stored).\na README file containing the basic details about the dataset and the repository\nan RMarkdown file which contains the mapping to the DwC standard.\n\nBy knitting the RMarkdown files, it’s also possible to generate a docs folder that can be used as a website (through GitHub pages), providing an easy access information for the general community.\n\n\n\nWorkflow for data ingestion using obisdi"
  },
  {
    "objectID": "datamining.html#additional-data-from-literature-and-repositories",
    "href": "datamining.html#additional-data-from-literature-and-repositories",
    "title": "4  Obtaining additional biodiversity data",
    "section": "4.2 Additional data from literature and repositories",
    "text": "4.2 Additional data from literature and repositories\n\n4.2.1 BioTIME\nBioTIME is a database containing time series of ecological data from the terrestrial, freshwater and marine realm. We downloaded the full database (available here) and using the metadata information we identified those marine studies (on the Europe region) which were not available on OBIS. This identification procedure was based on a fuzzy matching of the titles with the OBIS dataset titles. For those that were probably relevant, we manually checked the datasets to confirm its relevance.\nAt the end we identified 4 new datasets that could be included, and proceeded with the data ingestion.\n\n\n\n\n\n\nWarning\n\n\n\nAt this moment, only one of the identified datasets was already ingested. The others are under processing and will soon be ingested.\n\n\n\n\n4.2.2 Literature\nWe searched on Web of Science for articles that could potentially contain datasets valuable for our project. We used the following search string: TS=((marine OR ocean* OR coastal) AND ((“biodiversity data”) OR (dataset) OR (“time series” OR time-series)) AND (species OR occurrence OR biodiversity OR fauna) AND (europe* OR global)). From the returned list (~2000 articles) we (1) matched the titles with the dataset names or bibliographic citations from OBIS to verify if the dataset was already included on OBIS, and (2) screened (manually) to identify if the dataset was valuable. Note that this is not a systematic review, but an exploratory search. Because the number of records was considerably large and the screening involves evaluating the data quality and the methods that generated it, in this first phase of the project we screened the first 100 records (ordered by relevance), and will keep screening in the following months.\n\n\n4.2.3 Data repositories\nWe searched the data repositories FigShare, Zenodo, and Dryad for datasets linked with marine data on the region of our study. For each of those repositories, a distinct search strategy was applied, based on their structure. Dataset names were fuzzy matched with dataset titles on OBIS and those identified as not available on OBIS were screened to assess its relevance. In this first phase of the project we screened the first 50 records, and will keep screening in the following months.\nOnce one dataset is identified for inclusion, it will be ingested using the obisdi structure.\nCodes for obtaining the information from those data repositories are available on the last section.\n\n\n4.2.4 Other sources\nWe also received suggestions of datasets directly from the participants of the project. We checked if the suggested dataset was not already on OBIS and, if not, we ingested the dataset."
  },
  {
    "objectID": "datamining.html#additional-data-from-gbif",
    "href": "datamining.html#additional-data-from-gbif",
    "title": "4  Obtaining additional biodiversity data",
    "section": "4.3 Additional data from GBIF",
    "text": "4.3 Additional data from GBIF\nAfter we obtained the list of species occurring on the study area, we downloaded the occurrence data from GBIF. From the occurrence data, we identified the unique datasets from which the data came from. We then counted the number of data each dataset contributed to the final data. We selected those datasets that had a high contribution of data (more than 50000 occurrences) as potential datasets that could be included in OBIS.\nFor the datasets with potential for inclusion, we first identified those that are already part of OBIS and excluded them from the search. With the remaining datasets, we screened for relevance.\nThe harvesting of the datasets to OBIS is done with the contribution and approval of an OBIS node. To do that, we follow this procedure:\n\nAn issue is open on the GitHub repo https://github.com/iobis/obis-network-datasets, indicating the dataset\nOne of the OBIS nodes will review the issue and verify the relevance and quality of the dataset\nIf the dataset is deemed valuable, then the OBIS node approves it and its harvested to the OBIS dataset.\n\n\n\n\n\n\n\nNote\n\n\n\nOnly datasets with CC0, CC-BY or CC-BY-NC license were considered for inclusion. More information on the OBIS manual."
  },
  {
    "objectID": "datamining.html#zenodo",
    "href": "datamining.html#zenodo",
    "title": "4  Obtaining additional biodiversity data",
    "section": "5.1 Zenodo",
    "text": "5.1 Zenodo\n\n# Get records from Zenodo using API connection\n\n# Create a function to retrieve the records for a certain query\nget_zenodo &lt;- function(query){\n  response &lt;- httr::GET('https://zenodo.org/api/records',\n                        query = list(q = query,\n                                     size = 2000, page = 1))\n  \n  t_resp &lt;- httr::content(response, \"parsed\", encoding = \"UTF-8\")\n  \n  results &lt;- lapply(t_resp, function(x){\n    data.frame(title = x$title, doi = x$doi)\n  })\n  \n  results &lt;- do.call(\"rbind\", results)\n  \n  return(results)\n  \n}\n\nzen_results &lt;- get_zenodo(\"+access_right:open +resource_type.type:dataset +title:marine +title:species\")\n\nwrite.csv(zen_results, paste0(\"source_lists/zen_\", format(Sys.Date(), \"%d%m%Y\"), \".csv\"),\n          row.names = F)"
  },
  {
    "objectID": "datamining.html#figshare",
    "href": "datamining.html#figshare",
    "title": "4  Obtaining additional biodiversity data",
    "section": "5.2 FigShare",
    "text": "5.2 FigShare\n\n# Get records from FigShare using API connection\nlibrary(httr)\n\n# Create a function to retrieve the records for a certain query\nquery_fig &lt;- '{\n  \"item_type\": 3,\n  \"search_for\": \"(:title: marine OR :title: ocean OR :title: coastal) AND (:title: europe OR :title: global) AND (:title: species OR :title: biodiversity)\",\n  \"limit\": 1000,\n  \"offset\": 0\n}'\n\nget_figshare &lt;- function(query, maxtry = 7000){\n  \n  off &lt;- seq(0, maxtry, by = 1000)\n  \n  retnum &lt;- 1000\n  \n  k &lt;- 1\n  \n  allres &lt;- list()\n  \n  while(retnum == 1000 & k &lt;= length(off)) {\n    \n    query &lt;- gsub('\"offset\": [[:digit:]]*', paste0('\"offset\": ', off[k]), query)\n    \n    response &lt;- POST(\"https://api.figshare.com/v2/articles/search\", body=query, \n                     httr::add_headers(`accept` = 'application/json'), \n                     httr::content_type('application/json'))\n    \n    if (response$status_code != 200) {\n      results &lt;- data.frame(title = NA, doi = NA, resource_title = NA)\n      retnum &lt;- 1000\n    } else {\n      t_resp &lt;- httr::content(response, \"parsed\", encoding = \"UTF-8\")\n      \n      results &lt;- lapply(t_resp, function(x){\n        data.frame(title = x$title, doi = x$doi, resource_title = x$resource_title)\n      })\n      \n      results &lt;- do.call(\"rbind\", results)\n      \n      retnum &lt;- nrow(results)\n    }\n    \n    allres[[k]] &lt;- results\n    \n    k &lt;- k + 1\n    \n  }\n  \n  return(allres)\n  \n}\n\nfig_q1 &lt;- get_figshare(query_fig)\n\n# Bind all results\nfig_results &lt;- do.call(\"rbind\", fig_q1)\n\nwrite.csv(fig_results, paste0(\"source_lists/fig_\", format(Sys.Date(), \"%d%m%Y\"), \".csv\"),\n          row.names = F)"
  },
  {
    "objectID": "datamining.html#dryad",
    "href": "datamining.html#dryad",
    "title": "4  Obtaining additional biodiversity data",
    "section": "5.3 Dryad",
    "text": "5.3 Dryad\n\n# Get records from Dryad using API connection\nlibrary(httr)\n\n# Create a function to retrieve the records for a certain query\nget_dryad &lt;- function(query, maxtry = 2000, addstop = T, verbose = T){\n  \n  off &lt;- seq(1, ceiling(maxtry/100))\n  \n  retnum &lt;- 100\n  \n  k &lt;- 1\n  \n  allres &lt;- list()\n  \n  while(retnum == 100 & k &lt;= length(off)) {\n    \n    if (verbose) cat(\"Downloading page\", k, \"\\n\")\n    \n    response &lt;- httr::GET('https://datadryad.org/api/v2/search',\n                          query = list(q = query,\n                                       per_page = 100, page = k))\n    \n    if (response$status_code != 200) {\n      results &lt;- data.frame(title = NA, doi = NA, resource_title = NA)\n      retnum &lt;- 100\n    } else {\n      t_resp &lt;- httr::content(response, \"parsed\", encoding = \"UTF-8\")\n      \n      results &lt;- lapply(t_resp$`_embedded`$`stash:datasets`, function(x){\n        id &lt;- x$identifier\n        title &lt;- x$title\n        if (is.null(title)) {\n          title &lt;- \"NOT FOUND\"\n        }\n        data.frame(title = title, doi = id)\n      })\n      \n      results &lt;- do.call(\"rbind\", results)\n      \n      retnum &lt;- nrow(results)\n    }\n    \n    allres[[k]] &lt;- results\n    \n    k &lt;- k + 1\n    \n    if (addstop) {\n      Sys.sleep(5)\n    }\n    \n  }\n  \n  return(allres)\n  \n}\n\ndry_q1 &lt;- get_dryad(\"marine species europe\")\ndry_q1 &lt;- do.call(\"rbind\", dry_q1)\n\ndry_q2 &lt;- get_dryad(\"marine species global\")\ndry_q2 &lt;- do.call(\"rbind\", dry_q2)\n\n# Bind all results\ndry_results &lt;- rbind(dry_q1, dry_q2)\n\nwrite.csv(dry_results, paste0(\"source_lists/dry_\", format(Sys.Date(), \"%d%m%Y\"), \".csv\"),\n          row.names = F)"
  },
  {
    "objectID": "datamining.html#code-for-fuzzy-matching-from-data-repositories",
    "href": "datamining.html#code-for-fuzzy-matching-from-data-repositories",
    "title": "4  Obtaining additional biodiversity data",
    "section": "5.4 Code for fuzzy matching from data repositories",
    "text": "5.4 Code for fuzzy matching from data repositories\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(sf)\n\nzen &lt;- read.csv(\"source_lists/zen_23062023.csv\")\ndry &lt;- read.csv(\"source_lists/dry_23062023.csv\")\nfig &lt;- read.csv(\"source_lists/fig_23062023.csv\")\n\nfull &lt;- rbind(\n  zen[,c(\"title\", \"doi\")],\n  dry[,c(\"title\", \"doi\")],\n  fig[,c(\"title\", \"doi\")]\n)\n\n# Get OBIS datasets\n# Open study area shapefile\nstarea &lt;- st_read(\"~/Research/mpa_europe/mpaeu_studyarea/data/shapefiles/mpa_europe_starea_v2.shp\")\nstarea &lt;- st_bbox(starea)\n\n# Download list of all obis datasets in the study area\ndatasets &lt;- robis::dataset(\n  geometry = st_as_text(st_geometry(st_as_sfc(st_bbox(starea))))\n)\n\n#### PYTHON IMPLEMENTATION\nlibrary(reticulate)\nuse_python(\"/usr/local/bin/python3\")\n\nfuz &lt;- import(\"rapidfuzz\")\n\nsources &lt;- tolower(full$title)\n\ncompare &lt;- tolower(datasets$title)\n\nmatch_frat &lt;- match_title &lt;- rep(NA, length(sources))\n\ncli::cli_progress_bar(\"Running fuzzy matching...\", total = length(sources))\n\nfor (s in 1:length(sources)) {\n  frat &lt;- rep(NA, length(compare))\n  \n  for (z in 1:length(compare)) {\n    frat[z] &lt;- fuz$fuzz$ratio(sources[s], compare[z])\n  }\n  \n  match_title[s] &lt;- compare[which.max(frat)]\n  match_frat[s] &lt;- max(frat, na.rm = T)\n  \n  cli::cli_progress_update()\n}\ncli::cli_progress_done()\n\ncross_check &lt;- full\ncross_check$match_titles &lt;- match_title\ncross_check$fuzzy_ratio &lt;- match_frat\n#### END OF PYTHON IMPLEMENTATION\n\n# Save for external edition\nwrite_csv(cross_check, \"final_lists/datarepo_datasets_comparison.csv\")"
  },
  {
    "objectID": "methods-testing.html#point-process-framework",
    "href": "methods-testing.html#point-process-framework",
    "title": "5  Testing SDM methods",
    "section": "5.1 Point-process framework",
    "text": "5.1 Point-process framework\nAll modeling exercises were done considering a point process framework. Spatial Point Process Models (PPMs) are used to model any type of events that arise as points in space (Renner et al. 2015). Those points have random number and location, but are related to an underlying process. It was only recently that PPMs were more intensively applied to SDMs (Renner et al. 2015; Warton and Shepherd 2010), although widely used in spatial analysis (examples of applications range from disease mapping to detection of landslides; e.g. Lombardo, Opitz, and Huser (2018)).\nThe interest in PPMs for SDMs was mainly driven by the challenge of modelling presence-only data, when all the information available is the points where the species was registered (Fithian and Hastie 2013). Usually, one need to sample pseudo-absences (points that reflect places where the species is absent), but the number and place of pseudo-absences can have a great influence on models (Barbet-Massin et al. 2012). Instead, on a PPM framework, quadrature (or background) points are used as a device only to describe the available environmental conditions (Fithian and Hastie 2013). Points are sampled at random and the number of points can be chosen based on the accuracy of the likelihood estimate (Renner et al. 2015). In theory, all the points of the environment could be used, but this would increase computational time.\nIn the case of a PPM, and considering that the points does not present a strong bias, the resulting intensity of the point process can be used as a proxy to the suitability of the habitat (under the assumption that the species is more easily registered where the habitat suitability is higher) (Renner et al. 2015). One important point to note is that the results of any PPM model (and in general, any presence-only model) should not be interpreted as probability of occurrence, but instead as a relative occurrence rate (following (Merow, Smith, and Silander 2013)).\nPPMs are closely related to the widely used Maxent (Renner and Warton 2013). Indeed, even the pseudo-absence (or presence-background) modeling can approximate a Poisson point process model, under certain conditions (Renner et al. 2015; Warton and Shepherd 2010)."
  },
  {
    "objectID": "methods-testing.html#chosen-algorithms",
    "href": "methods-testing.html#chosen-algorithms",
    "title": "5  Testing SDM methods",
    "section": "5.2 Chosen algorithms",
    "text": "5.2 Chosen algorithms\nBased on Valavi et al. (2021) and in our previous experience, we selected the following algorithms to test:\n\nGLM (Generalized Linear Models)\nLASSO (LASSO Regularized GLM, through glmnet)\nMaxent (Maximum Entropy algorithm, through maxnet implementation)\nBRT (Boosted Regression Trees)\nRandomForest\n\nWe also considered for very experimental purposes one other implementation of Boosted Regression Trees (also called GBM - Gradient Boosting Model), the LightGBM. This machine learning method performs very well in machine learning tasks and is much faster than other GBM implementations. However, as it was designed for large datasets it can suffer from overfitting.\nGLMs were fitted with four variations: no weighting, naive-weighting, IWLR (Infinitely Weighted Linear Regression) and DWPR (Down-Weighted Poisson Regression). BRT were fitted with no weight and with naive-weighting. Random Forest were fitted with no-weighted classification and down-sampled classification.\nAlgorithms were implemented as modules in the obissdm package. This package was specifically designed to hold the primary functions utilized in our modeling framework, thus facilitating more comprehensive documentation."
  },
  {
    "objectID": "methods-testing.html#test-with-virtual-species",
    "href": "methods-testing.html#test-with-virtual-species",
    "title": "5  Testing SDM methods",
    "section": "5.3 Test with virtual species",
    "text": "5.3 Test with virtual species\nFor the first part of the SDM methods testing, we created 2 virtual species (in which we have full control of the generative process; for more information on virtual species see Leroy et al. (2015) and Zurell et al. (2010)). Because we know the true distribution of the virtual species, we can better explore the differences in performance of the distinct algorithms under distinct conditions (Meynard, Leroy, and Kaplan 2019). We performed a set of testings considering the following scenarios:\n\nTwo conditions of environmental data: all environmental variables known (species 101) and one variable unknown (Gaussian noise) (species 103)\nTwo sampling conditions: with bias and without bias\nTwo data availability conditions: low (30 points) and high (150 points)\n\nThis sums up to 8 modeling settings. Because the sampling process of points is random, we generated 10 samples of presence points for each species (yielding a total 80 models to be fitted). We also generated 10 samples (for each species) of presence-absence points to be used as independent evaluation datasets."
  },
  {
    "objectID": "methods-testing.html#model-fitting",
    "href": "methods-testing.html#model-fitting",
    "title": "5  Testing SDM methods",
    "section": "5.4 Model fitting",
    "text": "5.4 Model fitting\n\n5.4.1 Environmental data\nEnvironmental data for both the present period and for two future scenarios for the year 2100 (SSP2 and SSP5) were obtained from the new version of Bio-ORACLE (not published yet, but see Assis et al. (2018)) using the package biooracler. Specifically, for producing and fitting the models of the virtual species we used the following variables (all for surface):\n\nSea Temperature\nSalinity\nPhosphate\nTotal Phytoplankton\nBathymetry\n\nAll variables were cropped to the study area, but considering a buffer to expand it. Variables were masked to a bathymetry of -1500m\n\n\n5.4.2 Quadrature sampling\nQuadrature points were randomly sampled in a number of 150000. We chose this number using a Down-Weighted Poisson Regression over different numbers of quadrature points (Renner et al. 2015; El-Gabbas and Dormann 2018). The chosen number was enough to likelihood convergence in all species.\n\n\n5.4.3 Model tuning and evaluation\nFor model tuning and evaluation we used a spatial block cross-validation strategy, with 5 folds. Spatial block cross-validation is better suited for assessing spatial models, as it ensures that testing data will show at least a certain degree of environmental difference from the information used to train the model (Roberts et al. 2017). We tested two types of spatial blocks: grid blocks and latitudinal bins. In the first, a grid of squares with a certain size are defined over the study area and randomly assigned into folds, while in the second, the study area is divided in a fixed number of latitudinal bins which are randomly assigned into folds (e.g. Assis et al. (2023)).\nThe size of the block can be defined to reflect the spatial correlation between variables (Valavi et al. 2018). However, for this test we defined a fixed block size for all tests to improve the fitting speed. The size (5 degrees) is deemed large enough to provide environmental variability to the testing data.\nModels were evaluated using AUC (Area Under the Receiver-Operating-Characteristic Curve) and CBI (Continuous Boyce Index), which are better suited for presence-only models. We also obtained TSS (True Skill Statistics) for three distinct thresholds (Maximum Sensitivity + Specificity, P10 and Minimum Training Presence). Final predictions for both the current and future period were compared with the original species suitable area using the I statistic of niche overlap, with a higher niche overlap meaning that the model better reflected the original condition. Binary maps produced with the P10 threshold were compared with the binary occurrence maps of the virtual species using Jaccard.\n\n\n5.4.4 Results\nIn general, all models had a good performance, except for the classification Random Forest. Forest based methods are know to have problems with class imbalance, a problem solved with the down-sampled implementation. Some methods had an excellent performance both for model evaluation (AUC, CBI) and capacity of predicting a similar distribution than the true one (I, Jaccard metrics): LASSO, Maxent and BRT naive. Indeed, LASSO and Maxent were expected to behavior similarly as under the hood maxnet uses LASSO.\n\n\n\nAUC metrics for the virtual species testing.\n\n\n\n\n\nCBI metrics for the virtual species testing. Values below 0 indicates counter prediction (low values where presence was expected).\n\n\n\n\n\nTSS metrics for the virtual species testing.\n\n\n\n\n\nI metrics for the virtual species testing.\n\n\n\n\n\nI metrics for the virtual species testing considering the SSP1 scenario.\n\n\n\n\n\nJaccard metrics for the virtual species testing.\n\n\n\n\n\nExample showing the real distribution in the current period and the predicted distribution by 4 distinct models. Warmer colors are higher relative occurrence rate.\n\n\n\n\n\nExample showing the real distribution in the future period (SSP1 - 2100) and the predicted distribution by 4 distinct models. Warmer colors are higher relative occurrence rate.\n\n\nFrom those models, LASSO was the one with fastest tuning-prediction time.\n\n\n\nTSS metrics for the virtual species testing."
  },
  {
    "objectID": "methods-testing.html#test-with-real-species",
    "href": "methods-testing.html#test-with-real-species",
    "title": "5  Testing SDM methods",
    "section": "5.5 Test with real species",
    "text": "5.5 Test with real species\nFor the second part of the SDM methods testing, we selected 4 fish species occurring in our study area for which we had a good number of points coverage and, thus, a better knowledge of the current distribution of the species. We also chose those species because IUCN range maps are available and thus we could assess how well our models agree with the range maps (although we acknowledge that IUCN range maps can have important bias).\nWe tested in this part 4 algorithms that scored better with the virtual species test: LASSO, Maxent, BRT and RF Down-sampled.\nModel fitting followed the same methods described for the virtual species test. Occurrence data for the species were obtained from both OBIS and GBIF. To reduce bias, only 1 occurrence point per cell was kept. Ideally, this record pruning would also consider the spatial autocorrelation and points would be pruned in a distance that reduces such correlation (see for one application). However, calculating the spatial autocorrelation for each species that will be modeled can introduce a significant additional time. Thus, for those tests we considered two simpler strategies (although we will try one other approach in the future): (1) keeping 1 point per cell in the same resolution of the environmental variables and (2) keeping 1 point per cell in a grid with a coarsened resolution (the double of the environmental layers, 0.1 degrees).\nWe chose a set of environmental variables to be used with all 5 species: sea temperature, salinity, phosphate, total phytoplankton and sea water velocity. The correlation level of those variables is low, as assessed through VIF (Variance Inflation Factor) using the function vifstep with a threshold of 6 (package usdm, Naimi et al. (2013)). Despite the same set of variables was used to all species, the type of the variable varied according to the species’ mode of life (e.g. bottom temperature for benthic species). Data for the mode of life was obtained through an automated search in three databases: Sealifebase, Fishbase, and WoRMS. The search was done in this order, so that if the information was found in multiple sources, the first one was used. In case the information was not found for a particular species, the function tried to find the mode of life of the parent level. The function was also developed in a way to be conservative. So, if a species was registered as both benthic and pelagic, we used variables for benthic environment.\nFor benthic, demersal or pelagic species associated with the bottom we set variables describing conditions in the maximum depth. Mesopelagic species would be modeled with conditions for the mean depth, while both pelagic and species for which no information was found were set to be modeled with surface conditions.\n\n5.5.1 Results\nAgain, all models in general performed well, although the Maxent CBI result for Pagrus auriga was poor (counter prediction).\n\n\n\nMetrics for distinct fish species\n\n\nSpecies\nModel\nAUC\nCBI\n\n\n\n\nPagrus auriga\nLASSO NAIVE\n0.9579113\n0.6944080\n\n\nPagrus auriga\nMAXNET\n0.9278172\n-0.3580859\n\n\nPagrus auriga\nRF DOWNSAMPLED\n0.9526472\n0.4740936\n\n\nPagrus pagrus\nBRT NAIVE\n0.9729053\n0.7421134\n\n\nPagrus pagrus\nLASSO NAIVE\n0.9713942\n0.7885390\n\n\nPagrus pagrus\nMAXNET\n0.9535204\n0.7874382\n\n\nPagrus pagrus\nRF DOWNSAMPLED\n0.9767534\n0.7510097\n\n\nHippoglossus hippoglossus\nBRT NAIVE\n0.9267527\n0.6133649\n\n\nHippoglossus hippoglossus\nLASSO NAIVE\n0.9182766\n0.8043597\n\n\nHippoglossus hippoglossus\nMAXNET\n0.9297201\n0.8483099\n\n\nHippoglossus hippoglossus\nRF DOWNSAMPLED\n0.9410502\n0.9431927\n\n\nSolea solea\nBRT NAIVE\n0.9826825\n0.8899457\n\n\nSolea solea\nLASSO NAIVE\n0.9783434\n0.9247209\n\n\nSolea solea\nMAXNET\n0.9812059\n0.8305053\n\n\nSolea solea\nRF DOWNSAMPLED\n0.9841448\n0.9642206\n\n\n\n\n\n\n\nAggregating the points to a coarser resolution had a small effect in the results.\n\n\n\nAggregated (coarser resolution) points metrics for distinct fish species\n\n\nSpecies\nModel\nAUC\nCBI\n\n\n\n\nPagrus auriga\nLASSO NAIVE\n0.9668805\n0.6126929\n\n\nPagrus auriga\nMAXNET\n0.8952810\n-0.1096416\n\n\nPagrus auriga\nRF DOWNSAMPLED\n0.9534657\n0.3234745\n\n\nPagrus pagrus\nBRT NAIVE\n0.9727463\n0.7777396\n\n\nPagrus pagrus\nLASSO NAIVE\n0.9614321\n0.8900431\n\n\nPagrus pagrus\nMAXNET\n0.9678948\n0.6614255\n\n\nPagrus pagrus\nRF DOWNSAMPLED\n0.9743048\n0.8677961\n\n\nHippoglossus hippoglossus\nBRT NAIVE\n0.9206924\n0.7825685\n\n\nHippoglossus hippoglossus\nLASSO NAIVE\n0.8955754\n0.8044800\n\n\nHippoglossus hippoglossus\nMAXNET\n0.9132706\n0.8247683\n\n\nHippoglossus hippoglossus\nRF DOWNSAMPLED\n0.9321905\n0.9087753\n\n\nSolea solea\nBRT NAIVE\n0.9812337\n0.9058282\n\n\nSolea solea\nLASSO NAIVE\n0.9748347\n0.9123480\n\n\nSolea solea\nMAXNET\n0.9798795\n0.9078488\n\n\nSolea solea\nRF DOWNSAMPLED\n0.9833917\n0.9444118\n\n\n\n\n\n\n\nModels in general reflected the spatial distribution of the occurrence points well.\n\n\n\nDistribution model of Pagrus pagrus, according to LASSO and RF down-sampled. IUCN range map and occurrence points are shown on the first image.\n\n\nNone of the models showed high levels of agreement with the IUCN maps. This discrepancy could be caused by issues related to the expert range maps. However, it might also highlight a potential difficulty in selecting a method to binarize the models. In this study, we opted for the P10 threshold, which determines the value at which 90% of the presence points would be classified as ‘present’. This represents a relatively conservative approach, but alternative methods may yield better results.\n\n\n\nJaccard metric between binary distribution map (p10 threshold) and IUCN range maps for different models. STD refers to those modeled with the standard 1 point per cell, while AGG refers to the aggregated version.\n\n\nSpecies\nModel\nJaccard\n\n\n\n\nHippoglossus hippoglossus\nSTD LASSO NAIVE\n0.2535797\n\n\nHippoglossus hippoglossus\nSTD MAXNET\n0.2457328\n\n\nHippoglossus hippoglossus\nAGG BRT NAIVE\n0.2218551\n\n\nHippoglossus hippoglossus\nSTD RF DOWNSAMPLED\n0.0903114\n\n\nPagrus auriga\nSTD LASSO NAIVE\n0.3148879\n\n\nPagrus auriga\nSTD MAXNET\n0.2791559\n\n\nPagrus auriga\nAGG BRT NAIVE\nNA\n\n\nPagrus auriga\nSTD RF DOWNSAMPLED\n0.0520648\n\n\nPagrus pagrus\nSTD LASSO NAIVE\n0.4874864\n\n\nPagrus pagrus\nSTD MAXNET\n0.3373778\n\n\nPagrus pagrus\nAGG BRT NAIVE\n0.4464283\n\n\nPagrus pagrus\nSTD RF DOWNSAMPLED\n0.0558340\n\n\nSolea solea\nSTD LASSO NAIVE\n0.3025897\n\n\nSolea solea\nSTD MAXNET\n0.2486340\n\n\nSolea solea\nAGG BRT NAIVE\n0.2554269\n\n\nSolea solea\nSTD RF DOWNSAMPLED\n0.0972130\n\n\n\n\n\n\n\nNOTE: BRT model failed for Pagrus auriga when aggregated."
  },
  {
    "objectID": "methods-testing.html#overview-and-chosen-approach",
    "href": "methods-testing.html#overview-and-chosen-approach",
    "title": "5  Testing SDM methods",
    "section": "5.6 Overview and chosen approach",
    "text": "5.6 Overview and chosen approach\nBased on the findings presented here, it is suggested that both LASSO and Maxnet are viable options. Additionally, BRT and RF Down-weighted could be considered as potential candidates. Since LASSO and Maxnet are closely related, we recommend using LASSO due to its faster implementation.\n\n\n\n\n\n\nAvailability of codes\n\n\n\nThe codes for this modeling exercise are available on the GitHub repository iobis/mpaeu_sdm. However, the data is not available due to size limitations on GitHub. Soon this data will be available in other repository."
  },
  {
    "objectID": "methods-testing.html#references",
    "href": "methods-testing.html#references",
    "title": "5  Testing SDM methods",
    "section": "5.7 References",
    "text": "5.7 References\n\n\n\n\nAssis, Jorge, Filipe Alberto, Erasmo C. Macaya, Nelson Castilho Coelho, Sylvain Faugeron, Gareth A. Pearson, Lydia Ladah, et al. 2023. “Past Climate-Driven Range Shifts Structuring Intraspecific Biodiversity Levels of the Giant Kelp (Macrocystis Pyrifera) at Global Scales.” Scientific Reports 13 (1). https://doi.org/10.1038/s41598-023-38944-7.\n\n\nAssis, Jorge, Lennert Tyberghein, Samuel Bosch, Heroen Verbruggen, and Ester A Serrao. 2018. “Bio-ORACLE V2.0: Extending Marine Data Layers for Bioclimatic Modelling.” Global Ecology and Biogeography 27: 277:284. https://doi.org/10.1111/geb.12693.\n\n\nBarbet-Massin, Morgane, Frédéric Jiguet, Cécile Hélène Albert, and Wilfried Thuiller. 2012. “Selecting Pseudo-Absences for Species Distribution Models: How, Where and How Many?: How to Use Pseudo-Absences in Niche Modelling?” Methods in Ecology and Evolution 3 (2): 327–38. https://doi.org/10.1111/j.2041-210X.2011.00172.x.\n\n\nEl-Gabbas, Ahmed, and Carsten F. Dormann. 2018. “Improved Species-Occurrence Predictions in Data-Poor Regions: Using Large-Scale Data and Bias Correction with down-Weighted Poisson Regression and Maxent.” Ecography 41 (7): 1161–72. https://doi.org/10.1111/ecog.03149.\n\n\nFithian, William, and Trevor Hastie. 2013. “Finite-Sample Equivalence in Statistical Models for Presence-Only Data.” The Annals of Applied Statistics 7 (4). https://doi.org/10.1214/13-AOAS667.\n\n\nInman, Richard, Janet Franklin, Todd Esque, and Kenneth Nussear. 2021. “Comparing Sample Bias Correction Methods for Species Distribution Modeling Using Virtual Species.” Ecosphere 12 (3). https://doi.org/10.1002/ecs2.3422.\n\n\nLeroy, Boris, Christine N. Meynard, Céline Bellard, and Franck Courchamp. 2015. “Virtualspecies, an R Package to Generate Virtual Species Distributions.” Ecography 39 (6): 599–607. https://doi.org/10.1111/ecog.01388.\n\n\nLombardo, Luigi, Thomas Opitz, and Raphaël Huser. 2018. “Point Process-Based Modeling of Multiple Debris Flow Landslides Using INLA: An Application to the 2009 Messina Disaster.” Stochastic Environmental Research and Risk Assessment 32 (7): 2179–98. https://doi.org/10.1007/s00477-018-1518-0.\n\n\nMarmion, Mathieu, Miia Parviainen, Miska Luoto, Risto K. Heikkinen, and Wilfried Thuiller. 2008. “Evaluation of Consensus Methods in Predictive Species Distribution Modelling.” Diversity and Distributions, 11.\n\n\nMerow, Cory, Matthew J. Smith, and John A. Silander. 2013. “A Practical Guide to MaxEnt for Modeling Species’ Distributions: What It Does, and Why Inputs and Settings Matter.” Ecography 36 (10): 1058–69. https://doi.org/10.1111/j.1600-0587.2013.07872.x.\n\n\nMeynard, Christine N., Boris Leroy, and David M. Kaplan. 2019. “Testing Methods in Species Distribution Modelling Using Virtual Species: What Have We Learnt and What Are We Missing?” Ecography 42 (12): 2021–36. https://doi.org/10.1111/ecog.04385.\n\n\nNaimi, Babak, Nicholas A. S. Hamm, Thomas A. Groen, Andrew K. Skidmore, and Albertus G. Toxopeus. 2013. “Where Is Positional Uncertainty a Problem for Species Distribution Modelling?” Ecography 37 (2): 191–203. https://doi.org/10.1111/j.1600-0587.2013.00205.x.\n\n\nRenner, Ian W., Jane Elith, Adrian Baddeley, William Fithian, Trevor Hastie, Steven J. Phillips, Gordana Popovic, and David I. Warton. 2015. “Point Process Models for Presence-Only Analysis.” Edited by Robert B. O’Hara. Methods in Ecology and Evolution 6 (4): 366–79. https://doi.org/10.1111/2041-210X.12352.\n\n\nRenner, Ian W., and David I. Warton. 2013. “Equivalence of MAXENT and Poisson Point Process Models for Species Distribution Modeling in Ecology.” Biometrics 69 (1): 274–81. https://doi.org/10.1111/j.1541-0420.2012.01824.x.\n\n\nRoberts, David R., Volker Bahn, Simone Ciuti, Mark S. Boyce, Jane Elith, Gurutzeta Guillera-Arroita, Severin Hauenstein, et al. 2017. “Cross-Validation Strategies for Data with Temporal, Spatial, Hierarchical, or Phylogenetic Structure.” Ecography 40 (8): 913–29. https://doi.org/10.1111/ecog.02881.\n\n\nValavi, Roozbeh, Jane Elith, José J. Lahoz-Monfort, and Gurutzeta Guillera-Arroita. 2018. “blockCV: An r Package for Generating Spatially or Environmentally Separated Folds for k-Fold Cross-Validation of Species Distribution Models.” Edited by David Warton. Methods in Ecology and Evolution 10 (2): 225–32. https://doi.org/10.1111/2041-210x.13107.\n\n\n———. 2021. “Modelling Species Presence-Only Data with Random Forests.” Ecography 44 (12): 1731–42. https://doi.org/10.1111/ecog.05615.\n\n\nValavi, Roozbeh, Gurutzeta Guillera-Arroita, José J. Lahoz-Monfort, and Jane Elith. 2022. “Predictive Performance of Presence-Only Species Distribution Models: A Benchmark Study with Reproducible Code.” Ecological Monographs 92 (1). https://doi.org/10.1002/ecm.1486.\n\n\nWarton, David I., and Leah C. Shepherd. 2010. “Poisson Point Process Models Solve the “Pseudo-Absence Problem” for Presence-Only Data in Ecology.” The Annals of Applied Statistics 4 (3). https://doi.org/10.1214/10-AOAS331.\n\n\nZurell, Damaris, Uta Berger, Juliano S. Cabral, Florian Jeltsch, Christine N. Meynard, Tamara Münkemüller, Nana Nehrbass, et al. 2010. “The Virtual Ecologist Approach: Simulating Data and Observers.” Oikos 119 (4): 622–35. https://doi.org/10.1111/j.1600-0706.2009.18284.x."
  }
]